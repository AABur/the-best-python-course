1
00:00:00,031 --> 00:00:04,819
Привет, меня зовут Никита Соболев. Я основной разработчик CPython, работаю над типизацией

2
00:00:05,26 --> 00:00:10,388
и несколькими другими частями CPython. И здесь со мной Эрик Сноу. Эрик, не могли бы вы

3
00:00:10,428 --> 00:00:14,875
пожалуйста, представиться? Да, Эрик Сноу. Я являюсь основным разработчиком Python

4
00:00:15,817 --> 00:00:21,726
с 2012 года и участвовал в разработке ядра Python в некоторой степени и до этого,

5
00:00:21,786 --> 00:00:27,688
конечно. Я работал над множеством разных проектов. Я

6
00:00:27,748 --> 00:00:33,953
работаю в области программного обеспечения с 2006 года. Мне это очень нравится. Много действительно интересных

7
00:00:34,013 --> 00:00:38,957
задач, которые нужно решать, работая над Python. Также я многому научился,

8
00:00:39,678 --> 00:00:46,203
внося вклад в Python. И также я смог помочь улучшить ряд

9
00:00:46,323 --> 00:00:52,268
различных частей Python, включая систему импорта и особенно многие

10
00:00:52,308 --> 00:00:57,81
фундаментальные операции среды выполнения, отслеживание всех различных данных,

11
00:00:57,85 --> 00:01:04,778
которые использует среда выполнения Python. Итак, я начал проект, и я уверен, мы поговорим об этом

12
00:01:04,798 --> 00:01:12,128
подробнее, но я начал проект примерно десять лет назад, чтобы попытаться улучшить поддержку Python

13
00:01:12,388 --> 00:01:19,657
многоядерного параллелизма. И за эти 10 лет был достигнут большой прогресс.

14
00:01:19,697 --> 00:01:25,09
Я думаю, что мы здесь в основном для того, чтобы обсудить ваш потрясающий проект под названием

15
00:01:25,17 --> 00:01:31,476
Субинтерпретаторы. И я думаю, что это ответ на вашу задачу по многоядерному

16
00:01:31,896 --> 00:01:37,782
параллелизму. Не могли бы вы объяснить аудитории, что это такое и как они могут

17
00:01:37,922 --> 00:01:47,13
использовать это в своих интересах? Конечно. Давайте посмотрим. В любой программе у вас будет

18
00:01:47,23 --> 00:01:55,229
набор данных, который использует ваша программа. И этот набор данных можно представить себе

19
00:01:55,289 --> 00:02:04,171
просто как кусок памяти с данными, как бы застрявшими в разных местах. Что ж,

20
00:02:04,331 --> 00:02:10,037
среда выполнения Python ничем не отличается. У среды выполнения Python есть множество различных

21
00:02:10,237 --> 00:02:16,628
фрагментов данных, многие из которых являются объектами Python, которые она использует во время работы, будь то

22
00:02:17,35 --> 00:02:23,019
интерпретатор байт-кода, выполняющий какой-то код Python, или CAPI, вмешивающийся

23
00:02:23,099 --> 00:02:30,372
и выполняющий какую-то работу. Но он всегда оперирует какой-то частью этого состояния среды выполнения.

24
00:02:30,452 --> 00:02:39,664
Так вот, интересно то, что в Python, и в CPython было это

25
00:02:40,125 --> 00:02:47,038
понятие интерпретатора, которое представляет собой своего рода набор состояний среды выполнения, который мы

26
00:02:47,178 --> 00:02:54,087
используем для запуска Python. И затем у каждого потока есть свой собственный кусок состояния. И затем каждый

27
00:02:54,147 --> 00:02:58,012
поток также разделяет то, что находится в этом интерпретаторе. Таким образом, у вас есть своего рода

28
00:02:58,052 --> 00:03:03,739
иерархия, все потоки, а затем интерпретатор наверху. Ну, Python,

29
00:03:04,34 --> 00:03:10,086
CPython также поддерживает наличие нескольких интерпретаторов в одном процессе. И это

30
00:03:10,127 --> 00:03:17,388
так уже около 25 лет. Но это не та функция, которой люди

31
00:03:17,408 --> 00:03:21,093
пользовались. Она не была доступна для кода Python, так что она была строго в C

32
00:03:21,113 --> 00:03:26,741
API. Не многие о ней знали, поэтому не многие ее использовали. И это

33
00:03:26,841 --> 00:03:32,209
изменилось недавно, отчасти благодаря работе, которую я делал. Идея в том, что если у вас

34
00:03:32,249 --> 00:03:37,836
есть несколько таких интерпретаторов и они строго изолированы, данные в

35
00:03:38,057 --> 00:03:41,982
одном и данные в другом, что ж, когда вы работаете с одним интерпретатором в

36
00:03:42,042 --> 00:03:51,967
каком-то потоке, эта работа не влияет на другие интерпретаторы. И если у вас

37
00:03:52,027 --> 00:03:57,876
есть такой уровень изоляции, то, по сути, у каждого интерпретатора есть

38
00:03:57,956 --> 00:04:02,603
свой собственный GIL. И если у каждого интерпретатора есть свой GIL, то внезапно с этой

39
00:04:02,723 --> 00:04:08,191
изоляцией вы можете запускать в нескольких потоках разные интерпретаторы, и

40
00:04:08,211 --> 00:04:14,903
они будут... Эта изоляция означает, что вы действительно можете использовать настоящий многоядерный

41
00:04:14,923 --> 00:04:21,671
параллелизм, когда вы запускаете программу в нескольких интерпретаторах. Так что

42
00:04:21,732 --> 00:04:30,643
в основном у нас есть поток на уровне ОС, и этот поток запускает C API, который запускает интерпретатор Python.

43
00:04:30,683 --> 00:04:37,103
Это так? Да, более-менее. На самом деле, легко

44
00:04:37,183 --> 00:04:43,54
подумать: о, я запущу несколько интерпретаторов, и это то, что я получу.

45
00:04:43,58 --> 00:04:49,138
Но на самом деле, вы не запускаете интерпретатор, вы работаете в потоке,

46
00:04:49,178 --> 00:04:53,945
используя интерпретатор. Так что, по сути, интерпретатор — это данные. Я

47
00:04:53,965 --> 00:04:57,17
имею в виду, вы можете концептуально думать об этом как о чем-то, что вы запускаете, но на самом деле

48
00:04:57,21 --> 00:05:01,256
интерпретатор — это данные, и вы работаете относительно этих данных, вы

49
00:05:01,296 --> 00:05:09,247
переключаетесь на другой интерпретатор и запускаете свое что-то, будь то C или даже если

50
00:05:09,327 --> 00:05:15,867
это Python, вы работаете относительно этого интерпретатора. Так что главное в том, что...

51
00:05:16,107 --> 00:05:20,979
вы не говорите "запустить в этом интерпретаторе", вы говорите "переключиться на этот интерпретатор и

52
00:05:20,999 --> 00:05:25,609
затем запустить", а потом запустить любой код, который хотите. И когда он запустится, он будет работать

53
00:05:25,67 --> 00:05:29,719
относительно этого интерпретатора. Но по сути это то, что вы

54
00:05:29,739 --> 00:05:34,53
говорите, просто вы работаете в потоке, используя другой интерпретатор.

55
00:05:36,383 --> 00:05:45,444
И у каждого из них есть свой собственный GIL. И это позволяет нам запускать как задачи, нагружающие процессор, так и

56
00:05:45,484 --> 00:05:54,0
задачи ввода-вывода. Это верно? Да. И, конечно, вы сказали очень важную вещь,

57
00:05:54,181 --> 00:05:59,849
которую многие не знают, что эта функция существовала с Python 1.5, я

58
00:05:59,909 --> 00:06:06,098
полагаю. Да, примерно. Какова была первоначальная мотивация для этого? Какова была

59
00:06:06,238 --> 00:06:10,724
отправная точка? Когда вы думаете о программе, имеющей глобальные переменные, глобальные

60
00:06:10,744 --> 00:06:17,814
переменные, как правило, немного сложны. Для большой программы глобальные переменные могут быть

61
00:06:17,874 --> 00:06:23,436
проблемой. Немного сложнее управлять этими глобальными переменными, когда они

62
00:06:23,456 --> 00:06:29,747
используются разными функциями. Одна функция может влиять на глобальное состояние и так далее. Так что

63
00:06:29,787 --> 00:06:37,46
лучшие инженерные практики, как правило, поощряют нас избегать глобальных переменных

64
00:06:38,281 --> 00:06:43,33
и работать относительно какого-то определенного состояния, которое хорошо

65
00:06:43,39 --> 00:06:49,846
инкапсулировано. Так что это часть того, что произошло тогда, был этот толчок

66
00:06:49,886 --> 00:06:54,054
к тому, чтобы взять все эти накопившиеся глобальные переменные, особенно когда они

67
00:06:54,094 --> 00:07:00,465
работали над лучшей поддержкой многопоточности. Так что они взяли это

68
00:07:01,287 --> 00:07:05,294
состояние потока, создали структуру состояния потока и инкапсулировали все

69
00:07:05,334 --> 00:07:10,954
данные, которые нужны были потокам. А затем появилась структура состояния интерпретатора. В то

70
00:07:11,014 --> 00:07:14,298
же время, имело смысл добавить структуру состояния интерпретатора. Я думаю, что

71
00:07:14,318 --> 00:07:21,586
было также некоторое вдохновение от других сред выполнения, например, TCL, я думаю, имел эту

72
00:07:21,647 --> 00:07:27,313
концепцию субинтерпретаторов, которая была отчасти вдохновением. Так что было это

73
00:07:27,874 --> 00:07:31,638
инкапсулирование этих данных. Итак, не все глобальные переменные были удалены, но много

74
00:07:31,658 --> 00:07:36,075
чего было перенесено в это состояние интерпретатора. И вот с этого, в общем-то, все

75
00:07:36,115 --> 00:07:39,619
и началось. Со временем, конечно, добавлялось все больше и больше глобальных переменных,

76
00:07:39,659 --> 00:07:48,288
и мы как бы потеряли из виду эту идею инкапсуляции, отчасти потому, что

77
00:07:48,328 --> 00:07:55,395
среди основных разработчиков не было большого стремления получить несколько

78
00:07:55,415 --> 00:08:03,178
интерпретаторов в этом состоянии интерпретатора. Так что вот где все началось. Итак,

79
00:08:03,939 --> 00:08:09,007
сколько интерпретаторов вы можете реально запустить на среднем MacBook

80
00:08:09,067 --> 00:08:13,354
или чем-то подобном? У вас есть какие-нибудь цифры производительности? Да, я думаю,

81
00:08:13,475 --> 00:08:19,384
пару лет назад я просто запустил небольшой тест, чтобы посмотреть, сколько интерпретаторов

82
00:08:19,444 --> 00:08:25,068
я мог бы запустить одновременно, прежде чем у меня закончилась бы память. И я думаю, в то время

83
00:08:25,088 --> 00:08:29,652
точно не помню. Может быть, 80. Это кажется мало, но может быть, это было 80,

84
00:08:29,793 --> 00:08:35,078
что-то в этом роде. Вероятно, немного больше, но не намного. Просто

85
00:08:35,138 --> 00:08:40,643
потому что каждый интерпретатор задействует много памяти. В нем есть все модули,

86
00:08:40,703 --> 00:08:45,988
которые вы импортируете. В нем есть множество других состояний среды выполнения, много объектов. Так что это

87
00:08:46,028 --> 00:08:50,492
займет приличное количество памяти. Я не помню точно, сколько это было. Это

88
00:08:50,532 --> 00:08:58,503
было похоже на то, что инициализированный загруженный интерпретатор занимал около двух мегабайт оперативной памяти,

89
00:08:58,663 --> 00:09:01,789
или что-то в этом роде. Я точно не помню, но что-то в этом духе.

90
00:09:01,849 --> 00:09:08,964
Но на том этапе, на котором я сейчас нахожусь, одна из ключевых вещей, которые я исследую, — это как

91
00:09:09,004 --> 00:09:14,916
уменьшить количество памяти, используемое каждым интерпретатором, а также как сделать

92
00:09:14,956 --> 00:09:22,001
интерпретаторы быстрее запускающимися. Мм-хм. Я думаю, что мы достигли точки, когда

93
00:09:22,061 --> 00:09:26,966
нам нужно обсудить вехи проекта, потому что я помню, что

94
00:09:27,046 --> 00:09:32,392
впервые мы широко обсуждали субинтерпретаторы в сообществе Python примерно во времена

95
00:09:32,452 --> 00:09:40,2
Python 3.10. И после этого в эту функцию было добавлено много замечательных вещей,

96
00:09:40,581 --> 00:09:44,485
вроде GIL для каждого интерпретатора и тому подобное. Не могли бы вы поделиться всеми

97
00:09:44,625 --> 00:09:48,352
важными вехами проекта? Я расскажу вам немного истории.

98
00:09:48,413 --> 00:09:54,109
Я думаю, это даст нам то, что мы хотим. В 2014 году я работал над множеством

99
00:09:54,149 --> 00:09:58,962
вещей, и как основной разработчик, и как член сообщества Python.

100
00:10:04,628 --> 00:10:09,754
Как основным разработчикам, нам на самом деле не говорят, чем мы должны

101
00:10:09,814 --> 00:10:15,421
заниматься. Почти все — волонтеры. И поэтому каждый просто как бы

102
00:10:15,441 --> 00:10:20,267
работает над тем, над чем собирается работать. Иногда у их работодателя есть потребность,

103
00:10:20,427 --> 00:10:25,272
и они работают над этим. Но часто люди просто работают над вещами, которые их интересуют или

104
00:10:25,312 --> 00:10:32,055
они работают над вещами, которые, по их мнению, необходимо сделать сообществу Python. Так что это

105
00:10:32,095 --> 00:10:40,654
был случай, когда в 2014 году я разговаривал с кем-то, чьи мысли о технологиях я очень уважал,

106
00:10:41,536 --> 00:10:47,496
и их видения развития. И они

107
00:10:47,556 --> 00:10:52,603
указали, что, по их мнению, Python — мертвый язык, что меня очень

108
00:10:52,643 --> 00:10:57,949
удивило. Я спросил почему, и они сказали: ну, это потому что Python не

109
00:10:58,43 --> 00:11:05,758
имеет хорошей поддержки многоядерного параллелизма из-за GIL. И

110
00:11:07,12 --> 00:11:11,926
это довольно распространенное мнение. И определенно есть некоторые

111
00:11:11,986 --> 00:11:17,684
ограничения. Есть компромиссы. GIL предоставляет много преимуществ в конце концов. Так что,

112
00:11:18,966 --> 00:11:23,292
мы немного поговорили об этом, но с тех пор меня действительно поразило, что кто-то,

113
00:11:23,352 --> 00:11:28,42
кого я считал таким хорошо информированным и имеющим действительно хорошую точку зрения на вещи,

114
00:11:29,181 --> 00:11:36,813
просто имел неверные представления. И я решил, что нам действительно нужно что-то сделать,

115
00:11:36,913 --> 00:11:44,143
чтобы улучшить поддержку многоядерности в Python. Так что я потратил, и это

116
00:11:44,183 --> 00:11:48,87
всё мое свободное время, я потратил примерно следующий год, изучая все возможные варианты,

117
00:11:49,331 --> 00:11:53,958
рассматривая проблему, размышляя, что мы можем с этим сделать, будь то просто

118
00:11:54,019 --> 00:11:57,805
лучшее информирование об этом, что исторически не работало, или

119
00:11:58,105 --> 00:12:04,716
поиск какого-то возможного решения, которое используется в других языках. Один

120
00:12:04,736 --> 00:12:11,995
очевидный выбор — избавиться от GIL. Но одна вещь, с которой я столкнулся, была идея

121
00:12:13,036 --> 00:12:19,085
взять несколько интерпретаторов и довести эту идею изоляции до логического конца.

122
00:12:19,125 --> 00:12:23,051
Потому что в реализации CPython было много вещей,

123
00:12:23,071 --> 00:12:29,68
где эта изоляция между интерпретаторами нарушалась. И

124
00:12:29,741 --> 00:12:36,268
именно поэтому они были не так уж и полезны. И вот я посмотрел на

125
00:12:36,308 --> 00:12:40,536
возможности, сузил круг вопросов и посмотрел, знаете, типа, было ли это

126
00:12:40,576 --> 00:12:44,383
чем-то, что я мог бы сделать? Какие шаги потребовались бы? Какие технические

127
00:12:44,443 --> 00:12:49,112
проблемы пришлось бы решать? Знаете, какая часть этого была, скажем, в пределах моего

128
00:12:51,737 --> 00:12:58,96
уровня знаний? И все это, и с учетом всех этих факторов, я в итоге

129
00:12:59,761 --> 00:13:07,812
понял, что единственным возможным решением для меня было попытаться исправить несколько

130
00:13:07,832 --> 00:13:13,64
интерпретаторов и получить GIL для каждого интерпретатора. Так что я разобрался со всеми различными

131
00:13:13,7 --> 00:13:18,306
детальными шагами, которые нужно было предпринять, и в итоге оказалось, что было 4000 или 5000

132
00:13:18,346 --> 00:13:27,846
глобальных переменных, с которыми нужно было разобраться. И вот я начал с этого, создал

133
00:13:28,788 --> 00:13:35,558
структуру состояния времени выполнения, которая находится как бы над структурой состояния интерпретатора, и начал

134
00:13:35,798 --> 00:13:41,567
переносить все эти глобальные переменные в нее. Я создал инструменты для... Вот почему у нас

135
00:13:41,607 --> 00:13:48,737
есть C-анализатор. Да. Так я создал этот C-анализатор, чтобы мы могли убедиться, что

136
00:13:48,757 --> 00:13:52,602
мы не добавляем больше глобальных переменных. И это, я думаю, сработало довольно хорошо.

137
00:13:53,744 --> 00:13:59,452
И большая часть работы заключалась просто в том, чтобы брать глобальные переменные, перемещать их в состояние среды выполнения,

138
00:13:59,492 --> 00:14:06,141
а затем, если возможно, перемещать их в состояние интерпретатора. Пока

139
00:14:06,221 --> 00:14:12,089
наконец, мы не дошли до того момента, когда все, что оставалось переместить, — это переместить GIL из

140
00:14:12,129 --> 00:14:17,765
этого состояния среды выполнения в состояние интерпретатора. Так вот, что

141
00:14:17,825 --> 00:14:24,872
интересно, я начал обсуждения всего этого еще в 2015 году. Так что это было

142
00:14:25,073 --> 00:14:34,217
в преддверии 3.5. И я начал говорить о добавлении. Итак, одна часть — это изоляция

143
00:14:34,258 --> 00:14:39,322
интерпретаторов. Другая часть — предоставление доступа к нескольким интерпретаторам для кода на Python

144
00:14:39,362 --> 00:14:44,767
через модуль стандартной библиотеки. И я на самом деле открывал обсуждения по этому поводу еще в

145
00:14:44,787 --> 00:14:52,033
2017 году или, может быть, даже раньше. Мне нужно было бы посмотреть. Но в 2017-м, во времена

146
00:14:52,073 --> 00:14:59,846
периода 3.7, 3.6, где-то там. Так что тогда было много обсуждений.

147
00:14:59,966 --> 00:15:06,721
Я думаю, я создал PEP 554, который был первоначальным PEP для модуля стандартной библиотеки.

148
00:15:06,781 --> 00:15:17,808
Это было в 2018 году. И тогда мы начали обсуждения по этому поводу. Так что это

149
00:15:17,848 --> 00:15:23,655
продолжается уже некоторое время. И, опять же, почти все это в мое свободное время, как

150
00:15:23,736 --> 00:15:30,505
и большинство вкладов в Python. Так что дошло до того, что, э-э, два года назад для

151
00:15:30,625 --> 00:15:35,491
Python 3.12, добрались до GIL для каждого интерпретатора, и в итоге пришлось создать пару

152
00:15:35,552 --> 00:15:41,9
дополнительных PEP для этого, включая PEP 684, который посвящен GIL для каждого интерпретатора.

153
00:15:42,922 --> 00:15:51,701
И он был принят, и изменение вошло в Python 3.12. Я пытался протащить

154
00:15:52,222 --> 00:15:57,809
PEP для модуля стандартной библиотеки и в 3.12, но это не сработало. Он

155
00:15:57,889 --> 00:16:01,433
не попал в 3.13 по другим причинам, и мы могли бы поговорить об этом, конечно,

156
00:16:02,114 --> 00:16:11,326
но он был принят для 3.14, и как бы проскользнул в последнюю минуту, и мы все это

157
00:16:11,386 --> 00:16:17,702
слили, так что теперь он у нас есть. Это concurrent.interpreters. Это то,

158
00:16:17,722 --> 00:16:22,03
куда хотел его поместить руководящий совет. Я собирался просто сделать его модулем interpreters.

159
00:16:22,07 --> 00:16:28,741
Так что вы можете найти его в concurrent.interpreters. И теперь,

160
00:16:28,902 --> 00:16:34,551
как я уже сказал, на данный момент это своего рода основа для множества вещей, которые мы

161
00:16:34,572 --> 00:16:40,122
можем сделать. Как только вы дойдете до этого момента, появится тонна вещей, которые мы можем сделать на основе

162
00:16:40,183 --> 00:16:45,307
этого, которые интересны. Большая часть этой работы, которую я делал, была

163
00:16:45,327 --> 00:16:50,232
своего рода скучной частью, но я хотел довести нас до того момента, когда у нас есть эта

164
00:16:50,272 --> 00:16:53,735
основа, и теперь люди могут начать решать множество интересных задач,

165
00:16:53,835 --> 00:17:01,061
например, как использовать субинтерпретаторы, как использовать их эффективно, или, как я уже сказал,

166
00:17:01,121 --> 00:17:07,247
как сделать их быстрее и упростить общение между ними и

167
00:17:07,267 --> 00:17:12,279
сделать его более эффективным. как заставить их запускаться быстрее и использовать меньше памяти, и тому

168
00:17:12,359 --> 00:17:17,607
подобное. Есть множество интересных задач, которые нужно решить, которые

169
00:17:18,288 --> 00:17:26,64
теперь, с версии 3.14, как бы открыты для исследования всему миру. Вы также упомянули, что мы

170
00:17:26,72 --> 00:17:32,389
удалили много глобальных переменных из CPython. И я думаю, что одна из основных

171
00:17:33,23 --> 00:17:38,382
техник для удаления этих глобальных переменных заключалась в изоляции модулей. Не могли бы

172
00:17:38,403 --> 00:17:43,528
вы рассказать об этом немного подробнее? Итак, это одна из вещей, с которыми нужно разобраться

173
00:17:43,688 --> 00:17:50,536
прямо сейчас: модули расширения по умолчанию не работают с изолированными интерпретаторами.

174
00:17:50,616 --> 00:17:55,581
Вы не можете их импортировать. Если вы попытаетесь импортировать модуль, который

175
00:17:55,641 --> 00:18:05,152
явно не поддерживает это, то импорт завершится неудачей. Мы сделали это, потому что альтернатива —

176
00:18:05,192 --> 00:18:15,053
это, по сути, те же проблемы, что и при любом многопоточном подходе. Но

177
00:18:15,233 --> 00:18:18,576
в итоге, это особенно проблематично, если вы разделяете объекты между

178
00:18:18,636 --> 00:18:27,364
интерпретаторами. Это означает, что модуль расширения должен быть изолирован, как

179
00:18:27,404 --> 00:18:36,18
вы и говорите. И это означает три вещи. Во-первых, его нужно модифицировать для использования

180
00:18:36,261 --> 00:18:41,026
многофазной инициализации. Это реализация PEP 389. У нас есть руководство,

181
00:18:41,086 --> 00:18:50,037
которое говорит об этом. Но PEP 389 или многофазная инициализация, по сути, означает,

182
00:18:50,177 --> 00:18:56,945
что вместо того, чтобы модуль расширения имел функцию init, у него есть функция exec.

183
00:18:56,985 --> 00:19:03,43
И тогда система импорта, она как бы повторяет то, что описано в PEP

184
00:19:04,171 --> 00:19:11,103
451, который вводит состоянием модуля. Это то, над чем я работал. И это, это применяет

185
00:19:11,143 --> 00:19:18,703
ту идею, где у вас есть... Выполнение модуля отличается от

186
00:19:18,783 --> 00:19:22,949
инициализации. Инициализация включает создание объекта модуля,

187
00:19:23,47 --> 00:19:29,438
включает некоторую настройку, включает добавление его в sys.modules и множество

188
00:19:29,478 --> 00:19:37,605
других вещей, которые система импорта может сделать для вас. Но до PEP 451 и 489

189
00:19:38,406 --> 00:19:47,495
модули должны были делать это, или загрузчики, если хотите, должны были делать это явно, тогда как

190
00:19:47,515 --> 00:19:54,483
эти два PEP сделали так, что загрузчикам нужно было только выполнить модуль, а

191
00:19:54,503 --> 00:20:01,089
система импорта могла позаботиться об остальном. Так что PEP 489 предоставляет это, он дает вам

192
00:20:01,129 --> 00:20:09,287
модуль... и он не дает вам модуль. То, что он вам дает, это функция init.

193
00:20:09,648 --> 00:20:14,042
Вместо того чтобы выполнять всю инициализацию для модуля, все, что он делает, это настраивает

194
00:20:14,363 --> 00:20:20,431
по сути, спецификацию. Так что теперь функция init возвращает эту спецификацию, которую затем

195
00:20:20,511 --> 00:20:25,299
система импорта может использовать. Она может взять эту спецификацию, и часть спецификации заключается в том, что у нее есть

196
00:20:25,319 --> 00:20:31,768
куча слотов. И есть куча предопределенных слотов. Один из них — exec. Так что

197
00:20:31,849 --> 00:20:38,038
он вызовет, он будет искать этот exec-слот. Он получит его значение. И это значение —

198
00:20:38,198 --> 00:20:42,665
функция, и он выполнит эту функцию. И эта функция передается в

199
00:20:42,685 --> 00:20:48,382
модуль, и она делает все то, что раньше делала функция init модулей расширения.

200
00:20:48,482 --> 00:20:55,19
Так что переход от старой однофазной инициализации с функцией init,

201
00:20:55,25 --> 00:21:01,077
делающей всю работу, к многофазной инициализации, где у вас есть функция exec, а затем

202
00:21:01,117 --> 00:21:07,705
у вас есть определение модуля, этот переход довольно прост. Это вопрос добавления нескольких

203
00:21:07,766 --> 00:21:13,222
дополнительных строк кода, довольно прямолинейный. И в качестве преимущества вы

204
00:21:13,242 --> 00:21:20,256
получаете разнообразную поддержку для таких вещей, как перезагрузка модулей или другие вещи,

205
00:21:20,316 --> 00:21:25,273
которые модули расширения не могли делать раньше. Итак, изолированные модули, первый

206
00:21:25,333 --> 00:21:30,38
шаг — это многофазная инициализация, которую все равно всем следует сделать. А затем

207
00:21:30,42 --> 00:21:36,047
есть еще две части. Одна — просто начать использовать состояние модуля, которое было

208
00:21:36,107 --> 00:21:42,335
частью Python еще с версии Python 3.4, 3.3, что-то в этом роде. Оно существует

209
00:21:42,375 --> 00:21:51,303
уже давно. Итак, состояние модуля — это, по сути, когда модуль создается, вы

210
00:21:51,323 --> 00:21:55,228
получаете сегмент памяти, и затем модуль будет работать относительно этой

211
00:21:55,308 --> 00:21:59,354
памяти, а не относительно глобальных переменных. Так что это вроде того же самого,

212
00:21:59,394 --> 00:22:03,919
что нам пришлось делать с Python в целом, со средой выполнения. Взять эти

213
00:22:03,959 --> 00:22:08,665
глобальные переменные, переместить их в структуру, а затем работать относительно

214
00:22:08,726 --> 00:22:13,652
этого. У каждого модуля есть доступ к своему собственному состоянию. Но интересно то, что

215
00:22:13,672 --> 00:22:20,441
каждый объект модуля имеет свое собственное состояние модуля. Даже в одном и том же

216
00:22:20,461 --> 00:22:26,572
интерпретаторе у вас может быть несколько копий одного и того же модуля, и у каждой

217
00:22:26,612 --> 00:22:31,701
будет свое собственное состояние модуля, что довольно круто.Это дает ряд

218
00:22:31,761 --> 00:22:37,831
преимуществ. И затем, как часть этого, C API Python исторически

219
00:22:37,992 --> 00:22:44,85
поддерживал создание статических типов. И статические типы — это объекты, но они

220
00:22:44,97 --> 00:22:54,13
статически выделенные и статически ссылающиеся объекты, что означает, что

221
00:22:54,211 --> 00:22:58,941
они обязательно разделяются между всеми интерпретаторами. И проблема в том, что

222
00:22:59,444 --> 00:23:03,692
объекты-типы, даже статические типы, содержат другие объекты, и они

223
00:23:03,772 --> 00:23:09,564
изменяемы. Так, например, у вас есть __subclasses__ или слабые

224
00:23:09,604 --> 00:23:14,533
ссылки хранятся в объекте типа. У каждого объекта типа есть __dict__, который

225
00:23:14,874 --> 00:23:20,624
вы можете изменять во время выполнения. Так что вы не можете допустить, чтобы эти объекты просачивались

226
00:23:20,684 --> 00:23:26,273
между интерпретаторами, что означает, что вам придется потрудиться, чтобы

227
00:23:26,333 --> 00:23:31,3
заставить это работать. Альтернатива, рекомендуемое решение для модулей расширения,

228
00:23:31,34 --> 00:23:37,089
и это третья часть, — это перейти от использования статических типов к типам в куче.

229
00:23:37,149 --> 00:23:44,648
Это, вероятно, самая болезненная часть, особенно для очень больших

230
00:23:44,748 --> 00:23:50,339
модулей расширения. Это не обязательно очень болезненно, но это работа. Это

231
00:23:50,98 --> 00:23:57,031
нетривиально. Это не просто добавить пару строк здесь и там. Вам нужно сделать

232
00:23:57,292 --> 00:24:02,9
кучу маленьких изменений. Так что это не очень приятный опыт. Ужасно, но это

233
00:24:02,96 --> 00:24:07,549
много для действительно больших модулей расширения. Это также то, что, я не знаю,

234
00:24:07,85 --> 00:24:11,958
это просто то, что мы хотим сделать лучше. Интересно то, что

235
00:24:12,018 --> 00:24:18,451
для среды выполнения Python существует множество встроенных типов. Так что это была одна из

236
00:24:18,491 --> 00:24:23,298
сложных вещей. Вероятно, есть три или четыре разные, на самом деле,

237
00:24:23,318 --> 00:24:30,176
сложные вещи, которые мне пришлось решить при изоляции интерпретаторов. И одна из

238
00:24:30,237 --> 00:24:38,138
них — это встроенные типы. Потому что мы предоставляем ряд объектов в

239
00:24:38,198 --> 00:24:46,682
C API, разделяемых всем кодом в этом процессе, включая несколько

240
00:24:46,702 --> 00:24:53,072
интерпретаторов. Поэтому нам нужно было найти способ разделять все объекты, предоставляемые этим API,

241
00:24:53,853 --> 00:25:00,383
чтобы они работали в этой ситуации и не допускали утечки данных между интерпретаторами. Для

242
00:25:00,483 --> 00:25:06,993
одиночек, вроде None и т. п., это не было такой уж большой проблемой. Мы на самом деле

243
00:25:07,073 --> 00:25:11,78
решили это с помощью дополнительной детали, называемой бессмертными объектами, что является своего рода

244
00:25:11,86 --> 00:25:15,946
деталью реализации. Мы не выставляли это на всеобщее обозрение. Может быть, мы это сделаем

245
00:25:15,966 --> 00:25:22,195
когда-нибудь, но я не уверен. Но это была часть головоломки. Так что мы это решили.

246
00:25:22,375 --> 00:25:25,66
Можете, пожалуйста, объяснить, что значит "бессмертный" в этом контексте? Да, да, мы

247
00:25:25,7 --> 00:25:33,752
понимаем. Итак, в CPython у объектов есть счетчик ссылок. И это своего рода проблема по

248
00:25:34,407 --> 00:25:40,354
множеству причин, потому что этот счетчик ссылок является частью публичного C API. Но он

249
00:25:40,414 --> 00:25:44,66
также есть и в коде Python. Точно так же, есть счетчик ссылок. Все это невидимо для

250
00:25:44,76 --> 00:25:50,287
пользователей по большей части. Итак, бессмертный объект — это тот, который никогда не будет

251
00:25:50,387 --> 00:25:57,035
освобожден. Он никогда не будет очищен. И деталь реализации здесь в том,

252
00:25:57,115 --> 00:26:03,907
что мы просто устанавливаем счетчик ссылок на очень большое число. И поэтому, если вы когда-нибудь найдете

253
00:26:03,927 --> 00:26:10,957
объект, например, если вы попытаетесь, инструменты, которые у нас есть, я не помню точно, какие у нас

254
00:26:10,997 --> 00:26:15,524
есть... sys.getrefcount или что-то в этом роде. sys.getrefcount, да. Так что если

255
00:26:15,564 --> 00:26:21,192
вы вызовете это, вы обнаружите, что для некоторых объектов счетчик ссылок абсурдно высок,

256
00:26:21,632 --> 00:26:26,359
знаете, миллиарды, верно? И это намного выше, чем ваша программа могла бы

257
00:26:26,419 --> 00:26:33,873
на самом деле достичь. И это потому, что этот объект... Так, но это

258
00:26:33,933 --> 00:26:37,301
деталь реализации, мы могли бы потенциально сделать это другими способами, но это

259
00:26:37,361 --> 00:26:43,236
довольно эффективно делать это так. Итак, с бессмертными объектами они никогда не умирают,

260
00:26:43,436 --> 00:26:48,973
что означает, что нам не нужно беспокоиться о том, что объекты будут очищены

261
00:26:49,835 --> 00:26:55,063
между интерпретаторами и всяких сумасшедших вещах. Для статических объектов, я имею в виду,

262
00:26:55,083 --> 00:26:59,83
в любом случае имеет смысл, что они бессмертные объекты. Но еще одно преимущество в том,

263
00:26:59,93 --> 00:27:08,348
что для объектов, где единственным изменяемым состоянием является счетчик ссылок, тогда...

264
00:27:08,69 --> 00:27:13,09
теперь, в бессмертных объектах, мы устанавливаем значение на очень большое число, а затем мы никогда его

265
00:27:13,17 --> 00:27:18,661
не меняем. Так что оно остается там. Это означает, что больше нет гонок данных для

266
00:27:19,181 --> 00:27:25,051
объектов между интерпретаторами, если этот объект разделяется, как None, или один

267
00:27:25,111 --> 00:27:29,318
из статических типов, встроенных типов, тогда нам не нужно беспокоиться об этом счетчике

268
00:27:29,358 --> 00:27:33,565
ссылок, и тогда мы не столкнемся с какими-либо странными ситуациями, например, когда счетчик ссылок

269
00:27:33,605 --> 00:27:37,331
достигает нуля из-за состояний гонки, и мы не ожидали

270
00:27:37,371 --> 00:27:43,551
этого, или он переполняется, или что-то еще странное. Так что из-за этого бессмертные

271
00:27:43,691 --> 00:27:51,481
объекты действительно важны для облегчения использования объектов, разделения

272
00:27:51,601 --> 00:27:57,008
объектов между интерпретаторами безопасно, когда эти объекты, единственные изменяемые,

273
00:27:57,308 --> 00:28:05,765
фактически изменяемые данные — это счетчик ссылок. Так, например, целые числа, знаете, тип int,

274
00:28:05,986 --> 00:28:11,094
ну, для малых целых чисел мы на самом деле, куча этих малых целых чисел, таких как один и

275
00:28:11,334 --> 00:28:19,888
10 и минус один, все они статические, статически определены в CPython. Так что они

276
00:28:19,908 --> 00:28:23,174
не выделяются динамически. Они не принадлежат ни одному интерпретатору. Они

277
00:28:23,194 --> 00:28:28,222
принадлежат всем интерпретаторам. Они неизменяемы. И никакие их данные не изменяются,

278
00:28:28,262 --> 00:28:32,884
кроме счетчика ссылок, за исключением того, что они бессмертны. Теперь даже счетчик ссылок

279
00:28:32,924 --> 00:28:37,675
не меняется, и у нас нет проблем. У нас нет никаких гонок данных

280
00:28:37,735 --> 00:28:44,384
там. У нас нет проблем с трэшингом данных и промахами кэша и

281
00:28:46,047 --> 00:28:49,592
различными другими вещами, связанными с производительностью. Так что есть множество преимуществ,

282
00:28:49,672 --> 00:28:53,177
которые мы получаем от бессмертных объектов, но есть также определенные ограничения

283
00:28:53,918 --> 00:29:00,567
относительно изменяемости, которые мы должны учитывать. В этом вся суть

284
00:29:01,108 --> 00:29:08,756
бессмертных объектов. Вы можете посмотреть PEP 683, который полностью посвящен бессмертным объектам. Но,

285
00:29:08,816 --> 00:29:14,122
опять же, это все внутренние детали. Так что нет C API, связанного с бессмертными

286
00:29:14,222 --> 00:29:19,608
объектами, это публично. Так что мы использовали это со статическими типами, что замечательно,

287
00:29:20,449 --> 00:29:25,154
потому что у нас есть множество статических типов, которые доступны в C API напрямую. Не

288
00:29:25,254 --> 00:29:32,386
указатели на типы в стеке, а сам фактический статический тип. И поэтому мы

289
00:29:32,426 --> 00:29:38,475
сделали это, но все еще есть фактор __dict__ и __subclasses__ и

290
00:29:38,495 --> 00:29:44,064
слабых ссылок. Эти вещи все еще были изменяемыми и разделялись между интерпретаторами. Так что

291
00:29:44,124 --> 00:29:50,958
нам пришлось придумать эту хитрую уловку, где вместо поиска статических

292
00:29:51,018 --> 00:29:56,629
типов, мы не смотрим в... у статических типов есть куча полей. Это

293
00:29:56,649 --> 00:30:06,208
структура с кучей полей и слотом, например, tp_subclasses или tp_dict.

294
00:30:06,268 --> 00:30:13,312
Так что вместо того, чтобы, как обычно для объектов, когда мы что-то ищем

295
00:30:13,352 --> 00:30:19,221
в типе, и мы смотрим в tp_dict, и это словарь, или в tp_subclasses, и это

296
00:30:19,281 --> 00:30:25,05
список. И обычно мы смотрели туда. Но для статических типов у нас есть

297
00:30:25,171 --> 00:30:31,841
особый случай, когда для этих объектов мы на самом деле смотрим в состояние интерпретатора.

298
00:30:31,921 --> 00:30:45,189
Так что у нас есть массив маленьких структур, в которых есть подклассы, словарь и слабые

299
00:30:45,229 --> 00:30:51,897
ссылки, хранящиеся в этой маленькой структуре. И это массив из них. Так что есть индекс

300
00:30:52,118 --> 00:30:59,647
в массив для каждого из них. И теперь каждый статический тип знает свой индекс. И поэтому

301
00:30:59,727 --> 00:31:03,391
когда мы идем что-то искать, мы говорим: о, это статический тип. Мы получаем индекс из

302
00:31:03,431 --> 00:31:08,638
статического типа. А затем мы идем в этот массив в состоянии интерпретатора и смотрим

303
00:31:08,679 --> 00:31:15,349
его, и мы получаем запись, а затем мы получаем значение из структур, хранящихся в этом

304
00:31:15,389 --> 00:31:20,356
массиве. Верно. Да, это все довольно эффективно. И таким образом мы

305
00:31:20,417 --> 00:31:26,526
можем поддерживать изоляцию для тех немногих частей статических типов, которые

306
00:31:27,287 --> 00:31:33,378
изменяемы. И так мы это решили. Теперь, возвращаясь к модулям расширения,

307
00:31:33,698 --> 00:31:37,747
одна вещь, о которой мы думали, — это применить то же самое решение к модулям расширения,

308
00:31:37,787 --> 00:31:43,278
чтобы модулям расширения не приходилось переходить на использование типов в куче. Есть

309
00:31:43,298 --> 00:31:46,865
некоторые другие преимущества использования типов в куче, и мы призываем всех использовать

310
00:31:46,905 --> 00:31:52,377
типы в куче, но мы подумали, что это своего рода препятствие, потому что другие

311
00:31:52,457 --> 00:31:57,189
части поддержки или реализации изоляции модуля расширения действительно

312
00:31:57,209 --> 00:32:01,561
просты. Типы в куче. Они в порядке. Это не так уж много работы, но

313
00:32:01,581 --> 00:32:10,132
это достаточно работы, чтобы люди как бы сопротивлялись этому, что я понимаю.

314
00:32:10,152 --> 00:32:15,297
И поэтому мы подумали, что, хотя есть и другие преимущества использования типов в куче, и мы

315
00:32:15,337 --> 00:32:21,583
хотим, чтобы люди переходили на них, есть случаи, когда имеет смысл оставаться со

316
00:32:21,603 --> 00:32:27,71
статическими типами. Так что мы должны быть в состоянии найти способ применить, как один из возможных,

317
00:32:27,75 --> 00:32:33,215
вариантов, то же самое решение, которое мы используем для статических типов в среде выполнения,

318
00:32:33,255 --> 00:32:40,278
встроенных типов, применить то же самое для статических типов и модулей расширения. Мы

319
00:32:40,298 --> 00:32:45,244
еще не дошли до этого, но это одна из вещей, которые я буду изучать. Так что это

320
00:32:45,645 --> 00:32:51,913
позволит людям намного проще изолировать свои модули. Есть

321
00:32:52,013 --> 00:32:57,46
еще одна вещь, которую люди должны учитывать, — это то, что если модуль расширения

322
00:32:58,101 --> 00:33:04,866
использует какую-либо библиотеку, например, библиотеку C, которая сама по себе

323
00:33:05,487 --> 00:33:12,597
не имеет изолированного состояния, то модулю расширения придется работать

324
00:33:12,658 --> 00:33:19,007
в обход этого. Например, модуль SSL. Да, модуль SSL, именно. Так что

325
00:33:19,648 --> 00:33:23,613
это то, с чем людям приходится иметь дело. И если я правильно помню, это

326
00:33:23,633 --> 00:33:29,827
на самом деле возникло с библиотекой cryptography, которая есть на PyPI и довольно

327
00:33:29,867 --> 00:33:34,493
популярна. И они столкнулись с этим, когда кто-то использовал cryptography с

328
00:33:35,194 --> 00:33:39,438
субинтерпретаторами тогда. Это было, я не знаю, 10 лет назад, где-то так. И

329
00:33:39,458 --> 00:33:45,265
они на самом деле не могли понять, что происходит, но потом они выяснили, что

330
00:33:45,305 --> 00:33:52,259
это была проблема с несколькими интерпретаторами, и с модулем SSL что-то было не так

331
00:33:52,319 --> 00:33:58,507
с OpenSSL. И они не могли отслеживать между интерпретаторами,

332
00:33:59,828 --> 00:34:05,696
замену состояния и все, что нужно делать с OpenSSL. И поэтому им пришлось

333
00:34:05,736 --> 00:34:10,642
обойти это. И это то, что, возможно, придется делать людям. Я

334
00:34:10,682 --> 00:34:15,629
ожидаю, что это действительно редкость. Это своего рода дополнительная деталь, но я ожидаю, что это не

335
00:34:15,669 --> 00:34:22,019
сильно повлияет на многих людей. А если и повлияет, то будет довольно

336
00:34:22,119 --> 00:34:28,545
ясно, что происходит и что им нужно с этим делать. Так что вот где-то там

337
00:34:28,585 --> 00:34:33,731
находятся модули расширения. Так что я надеюсь, что на данный момент, когда у нас есть все части на месте,

338
00:34:33,771 --> 00:34:38,456
мы сможем, и у нас есть мотивация для людей переходить на

339
00:34:38,496 --> 00:34:42,56
многофазную инициализацию и изолированные модули расширения, и мы увидим гораздо больше этого

340
00:34:42,62 --> 00:34:48,849
в сообществе. Одна интересная вещь заключается в том, что многое из того,

341
00:34:48,869 --> 00:34:53,258
что вам нужно сделать для поддержки нескольких интерпретаторов и изолированных

342
00:34:53,298 --> 00:34:59,59
интерпретаторов, — это в точности то же самое, что вам придется сделать для поддержки free

343
00:34:59,63 --> 00:35:06,983
threading. Так что в сборке Python с free threading вы сталкиваетесь со всеми теми же

344
00:35:07,924 --> 00:35:14,956
гонками данных и... Вероятно, даже с большим их количеством. Да, даже больше. Есть пара

345
00:35:15,216 --> 00:35:21,146
небольших крайних случаев, которые специфичны для нескольких интерпретаторов, но в основном все

346
00:35:21,186 --> 00:35:25,633
то же самое, с чем вы сталкиваетесь там, вы сталкиваетесь и с несколькими интерпретаторами. Так что почти

347
00:35:25,673 --> 00:35:32,816
вся работа, которую людям придется проделать, чтобы быть совместимыми с free

348
00:35:32,856 --> 00:35:37,967
threading в модулях расширения, — это работа, которую им пришлось бы сделать для поддержки

349
00:35:38,187 --> 00:35:44,801
изолированных интерпретаторов, что приятно. И людям, похоже,

350
00:35:44,842 --> 00:35:48,748
гораздо больше хочется поддерживать free threading, чем

351
00:35:48,788 --> 00:35:53,677
поддерживать несколько интерпретаторов на данный момент. Так что, знаете, я ожидаю, что это

352
00:35:53,717 --> 00:35:59,206
изменится со временем, но приятно, что есть немного больше мотивации для

353
00:35:59,266 --> 00:36:05,977
людей делать всю эту работу. Хорошо, раз уж мы затронули free threading, давайте

354
00:36:06,037 --> 00:36:10,425
обсудим различия и возможности этих двух функций,

355
00:36:10,465 --> 00:36:14,652
работающих вместе. По моему мнению, я поделюсь своим мнением о free threading:

356
00:36:15,133 --> 00:36:18,419
использование потоков очень сложно из-за гонок данных, из-за

357
00:36:18,579 --> 00:36:25,848
неизменяемой природы CPython. И я думаю, что, поскольку у меня опыт работы с Erlang,

358
00:36:25,868 --> 00:36:31,133
мне очень нравится модель акторов и неизменяемые структуры данных.

359
00:36:31,674 --> 00:36:36,178
И мне очень трудно думать об изменяемости, о добавлении блокировок, о

360
00:36:36,519 --> 00:36:40,743
добавлении мьютексов и всех этих примитивов синхронизации ко всей

361
00:36:40,823 --> 00:36:46,809
вашей кодовой базе. И то, что субинтерпретаторы решают для меня, — это освобождает меня от этой

362
00:36:46,869 --> 00:36:52,777
проблемы. Вы согласны с этим? Да. Интересно, когда вы думаете

363
00:36:52,837 --> 00:36:57,263
о потоках, там есть много замечательных вещей, которые они приносят, и поэтому

364
00:36:57,303 --> 00:37:04,714
люди... почему они существуют десятилетиями. Верно. Эм, но есть много

365
00:37:04,794 --> 00:37:09,561
хорошо известных проблем. Как вы говорите, гонки данных, у вас есть целая

366
00:37:09,601 --> 00:37:15,449
программа в вашем процессе, и все потоки в этом процессе разделяют всю

367
00:37:15,49 --> 00:37:22,804
память и все ресурсы в этом процессе. И, эм, у вас нет гарантий

368
00:37:22,964 --> 00:37:29,712
относительно того, к каким данным будет обращаться код, выполняющийся в данном потоке, может быть, изменять их,

369
00:37:29,893 --> 00:37:35,44
что угодно. Когда вы пишете программу, есть данные, которые вы используете, и

370
00:37:35,64 --> 00:37:41,928
вы можете попытаться быть дисциплинированным, чтобы убедиться, что любые данные, которые вы

371
00:37:42,048 --> 00:37:46,874
используете в нескольких потоках, вы используете очень осторожно. Вы практикуете всевозможные

372
00:37:46,914 --> 00:37:53,401
меры потокобезопасности, чтобы не столкнуться с проблемами. И так вы делаете, но

373
00:37:53,441 --> 00:37:59,828
затем вам также нужно убедиться, что вы случайно не разделяете никакие другие данные

374
00:37:59,868 --> 00:38:04,734
между потоками. Вы должны убедиться, что любые зависимости, которые у вас есть, любые

375
00:38:04,834 --> 00:38:13,083
библиотеки, также потокобезопасны. И поскольку все данные, которые они используют,

376
00:38:13,163 --> 00:38:20,44
подвержены проблемам потокобезопасности. И поэтому это просто не укладывается в человеческий

377
00:38:20,48 --> 00:38:28,916
мозг. Плюс идея о том, что потоки работают одновременно и что-то делают,

378
00:38:28,956 --> 00:38:32,462
и у вас на самом деле нет никакой естественной синхронизации между ними.

379
00:38:33,183 --> 00:38:36,65
Мозгу действительно трудно об этом думать. Это просто не очень подходит

380
00:38:36,73 --> 00:38:43,191
людям. Так что эти проблемы действительно делают это вызовом. И гораздо лучше,

381
00:38:43,211 --> 00:38:51,625
если вы можете взять эту идею: о, потоки, они разделяют все данные в процессе,

382
00:38:51,866 --> 00:38:56,814
и вы сужаете ее до: я явно контролирую, какие данные потоки могут

383
00:38:56,855 --> 00:39:06,399
разделять. Но вы явно выбираете, какие данные вы разделяете. И это

384
00:39:06,459 --> 00:39:11,307
по сути то, что связано с несколькими интерпретаторами. Потому что то, что

385
00:39:11,347 --> 00:39:16,775
вы делаете, — по умолчанию они изолированы. И затем любой механизм, который вы

386
00:39:16,895 --> 00:39:22,563
используете для передачи данных между ними, будь то объекты или что-то еще, вы должны

387
00:39:22,623 --> 00:39:33,822
явно сказать, что этот механизм, который я добавляю для общения

388
00:39:33,862 --> 00:39:39,348
между интерпретаторами, ну, вы должны явно сказать: "Хорошо, эти данные, которые я

389
00:39:39,388 --> 00:39:46,717
передаю, я знаю, как обеспечить их безопасность между интерпретаторами. И я знаю, как

390
00:39:47,037 --> 00:39:50,981
обеспечить их безопасность, если я разделяю их между интерпретаторами. Я явно управляю

391
00:39:51,041 --> 00:39:57,587
этим. И поэтому я могу управлять этой узкой областью между интерпретаторами намного лучше, чем

392
00:39:57,667 --> 00:40:02,635
управлять всем возможным обменом данными, который происходит между потоками во

393
00:40:02,755 --> 00:40:09,926
всем пространстве программы. Явное всегда лучше неявного. Да. У вас

394
00:40:09,966 --> 00:40:15,839
есть примеры использования, где они работают вместе лучше, чем поодиночке? Хорошо, так

395
00:40:16,36 --> 00:40:19,965
во-первых, я отмечу, и я уже упоминал об этом ранее, что вы

396
00:40:20,005 --> 00:40:25,413
не работаете в интерпретаторе, вы работаете в потоке, верно? Так что все, что вы делаете, это

397
00:40:25,453 --> 00:40:29,819
переключаетесь между потоками. Так что для использования нескольких интерпретаторов, вам нужно использовать,

398
00:40:29,939 --> 00:40:34,326
ну, вам не обязательно использовать, но чтобы наилучшим образом использовать это, вы используете несколько

399
00:40:34,366 --> 00:40:38,021
потоков. Так что если вы хотите, чтобы несколько интерпретаторов работали одновременно,

400
00:40:38,041 --> 00:40:41,425
вам нужно, чтобы несколько потоков работали одновременно. Вы запускаете один

401
00:40:41,485 --> 00:40:45,21
поток и переключаетесь на другой интерпретатор в этом потоке и работаете

402
00:40:45,25 --> 00:40:51,117
относительно этого интерпретатора. Так что вы не можете реально использовать несколько

403
00:40:51,137 --> 00:40:56,644
интерпретаторов без потоков. Но то, что делают несколько интерпретаторов, — это дают

404
00:40:56,664 --> 00:41:01,67
вам изоляцию с потоками, чтобы потоки не могли выйти за границы

405
00:41:01,73 --> 00:41:06,455
интерпретаторов. Они не будут использовать данные всей

406
00:41:06,795 --> 00:41:11,041
программы. Они будут использовать только данные в интерпретаторе. В противном случае,

407
00:41:11,862 --> 00:41:16,288
я не уверен в лучшем решении. Я работал над некоторыми руководствами

408
00:41:16,328 --> 00:41:20,914
для этого. И некоторые из примеров, которые я написал, включают: "Хорошо,

409
00:41:20,934 --> 00:41:28,565
я собираюсь создать поток, который будет ставить в очередь задачи или что-то еще. И я

410
00:41:28,585 --> 00:41:34,556
собираюсь использовать для этого поток, потому что я буду использовать, это действительно простой

411
00:41:34,676 --> 00:41:39,764
случай использования потоков, и это здорово. Потоки довольно просты и легки в использовании. С

412
00:41:39,984 --> 00:41:43,049
несколькими интерпретаторами вам нужно думать о границе между

413
00:41:43,069 --> 00:41:47,977
интерпретаторами. И поскольку они изолированы, вы должны думать: хорошо, если я

414
00:41:48,017 --> 00:41:51,923
собираюсь общаться между этими интерпретаторами, как я буду

415
00:41:51,983 --> 00:41:55,882
общаться? В каких точках я буду общаться между интерпретаторами? И

416
00:41:55,902 --> 00:41:58,526
это своего рода точка синхронизации. И вам нужно немного подумать

417
00:41:58,586 --> 00:42:03,073
по-другому. Вы не можете просто сказать: "О, я просто изменю эту переменную". И

418
00:42:03,133 --> 00:42:09,263
вдруг мой другой поток сможет это использовать. Вы должны явно

419
00:42:09,323 --> 00:42:13,83
сказать: "Хорошо, я отправляю эти данные в другой интерпретатор". И теперь он будет

420
00:42:13,87 --> 00:42:19,979
делать свое дело с этими данными и так далее. В некоторых случаях проще использовать поток для

421
00:42:20,52 --> 00:42:24,922
настройки вычисления, а затем использовать интерпретатор для выполнения фактической изолированной

422
00:42:25,002 --> 00:42:30,549
работы, чтобы у вас были эти тщательно управляемые границы и изоляция,

423
00:42:30,589 --> 00:42:34,835
которая дает вам это концептуальное преимущество. Просто гораздо легче думать

424
00:42:34,895 --> 00:42:42,004
об этих изолированных потоках операций с очень четкими точками, в которых

425
00:42:42,064 --> 00:42:46,222
вы общаетесь и синхронизируетесь между ними. Вы

426
00:42:46,263 --> 00:42:52,493
знакомы с Erlang и его моделью акторов? Не очень. Я имею в виду, есть много

427
00:42:52,694 --> 00:43:00,026
концептуальных сходств. В Erlang это действительно более фундаментально относительно

428
00:43:00,066 --> 00:43:05,896
того, как он работает, тогда как Python — это лишь один из множества различных способов, которыми вы

429
00:43:05,936 --> 00:43:11,796
можете реализовать параллелизм. Я очень увлечен идеей, что вы можете создать такого рода

430
00:43:11,896 --> 00:43:16,101
изоляцию между различными интерпретаторами, и вы можете отправлять сообщения

431
00:43:16,121 --> 00:43:21,487
разным частям вашей программы. И вы можете сделать это в Erlang, вы можете сделать это двумя

432
00:43:21,527 --> 00:43:26,172
способами. Вы можете сделать это асинхронно, так что вы просто отправляете сообщение и забываете о нем, или

433
00:43:26,212 --> 00:43:31,237
вы можете ждать ответа. Так что, по сути, у вас есть два варианта, и вы

434
00:43:31,278 --> 00:43:37,304
можете решить, какую логику вы предпочитаете в данном конкретном случае. Я бы хотел увидеть

435
00:43:37,344 --> 00:43:45,275
что-то подобное в CPython. Может быть, кто-то внесет это в ядро Python

436
00:43:45,316 --> 00:43:49,822
или, может быть, в какую-то другую стороннюю библиотеку. Было бы замечательно это

437
00:43:49,862 --> 00:43:56,511
увидеть. Ну, в этом-то и прелесть. С тем, где мы сейчас находимся, вся основа

438
00:43:56,551 --> 00:44:01,318
на месте, и теперь люди могут строить на этом. Они могут делать именно то, о чем вы

439
00:44:01,338 --> 00:44:05,24
говорите, и они должны быть в состоянии сделать это через модули расширения. Так что это

440
00:44:05,62 --> 00:44:12,269
то, что является опцией прямо сейчас. На самом деле, частью... так что на раннем этапе стало

441
00:44:12,349 --> 00:44:18,156
ясно, что предоставление доступа к нескольким интерпретаторам для кода Python через

442
00:44:18,196 --> 00:44:27,368
модуль стандартной библиотеки было полезно в некотором смысле, но было бы гораздо полезнее, если

443
00:44:27,408 --> 00:44:32,377
был бы способ фактически общаться между интерпретаторами. Так что на раннем этапе я

444
00:44:32,578 --> 00:44:39,247
добавил функциональность. Изначально я добавил каналы, вроде CSP, что означает

445
00:44:39,307 --> 00:44:45,395
взаимодействующие последовательные процессы, еще из 60-х. И это все еще часть

446
00:44:45,455 --> 00:44:52,2
различных языков программирования, много вдохновения оттуда. Рано, да, и Go

447
00:44:52,221 --> 00:44:58,191
имеет каналы, хотя мы могли бы поговорить и об этом. У меня есть мысли на этот счет. Так что

448
00:44:59,053 --> 00:45:03,982
каналы, я реализовал каналы для этого, и вы могли передавать вещи между

449
00:45:04,262 --> 00:45:08,69
каналами или между интерпретаторами, используя каналы. Так что это как бы управляло этим пространством

450
00:45:08,791 --> 00:45:15,445
между интерпретаторами, поддерживало потокобезопасность и все такое. И в основном это бы

451
00:45:15,485 --> 00:45:20,529
поддерживало эффективное создание копий объектов, но все же копий. Так что

452
00:45:20,549 --> 00:45:26,454
это на самом деле не разделяло объекты между интерпретаторами. В конце концов, я понял,

453
00:45:26,554 --> 00:45:30,398
что, вероятно, было бы лучше начать с чего-то более знакомого, например, с очередей,

454
00:45:30,758 --> 00:45:36,843
как модуль queue. Так что queue.Queue создал реализацию очереди, которая поддерживает

455
00:45:38,625 --> 00:45:47,818
передачу данных между интерпретаторами. Это было частью 734, который является своего рода

456
00:45:47,978 --> 00:45:54,847
заменой PEP 554, который я первоначально имел. PEP 734 был немного проще,

457
00:45:55,548 --> 00:46:03,198
и в нем были эти очереди. Так что прямо сейчас в 3.14 вы можете использовать эти очереди для передачи данных

458
00:46:03,278 --> 00:46:11,324
между интерпретаторами. Есть некоторые объекты, где это действительно... Когда вы

459
00:46:11,424 --> 00:46:16,111
отправляете что-то через очередь, оно, с другой стороны, когда его извлекают

460
00:46:16,151 --> 00:46:22,42
из очереди, не создаст фактическую копию. Оно создаст новый объект, но объект

461
00:46:22,52 --> 00:46:30,232
будет оборачивать базовые данные. Так что это случай для этих очередей, через

462
00:46:30,292 --> 00:46:39,832
очередь, с другой стороны вы получаете очередь, которая использует те же самые базовые данные,

463
00:46:40,133 --> 00:46:47,047
фактическую "сырую" очередь, которая реализована на C. Так что она на самом деле будет разделяться в обоих

464
00:46:47,127 --> 00:46:52,585
интерпретаторах, и таким образом вы можете протаскивать вещи через очередь. Другая сущность,

465
00:46:52,885 --> 00:46:58,313
где на самом деле разделяются внутренние данные, — это memoryview, что интересно,

466
00:46:58,533 --> 00:47:06,724
потому что таким образом, если у вас есть объект bytes или bytearray, или у вас есть NumPy

467
00:47:07,004 --> 00:47:12,712
массив, или что-либо, что реализует протокол буфера, вы можете разделять их, вы

468
00:47:13,133 --> 00:47:17,623
оборачиваете это в memoryview, а затем разделяете memoryview между ними, и с другой

469
00:47:17,683 --> 00:47:23,067
стороны очереди вы получите memoryview, memoryview, который оборачивает тот же самый

470
00:47:23,107 --> 00:47:32,675
буфер. Так что теперь, ну, почти никакие объекты на самом деле не разделяются между

471
00:47:32,735 --> 00:47:40,001
интерпретаторами, и большинство изменяемых объектов на самом деле копируются. Тем не менее, есть этот

472
00:47:40,141 --> 00:47:44,765
один тип данных, memoryview, где внутренние данные на самом деле разделяются, и

473
00:47:44,845 --> 00:47:50,466
вы потенциально можете использовать это для общения между интерпретаторами. Вы можете разделять

474
00:47:50,506 --> 00:47:55,445
массивы NumPy между интерпретаторами, что является довольно важным, потому что

475
00:47:55,787 --> 00:48:03,392
альтернативы немного сложнее. Например, с несколькими процессами вы не можете

476
00:48:03,432 --> 00:48:08,099
реально копировать массивы NumPy, и там есть всякие хитрости. Так что это

477
00:48:08,499 --> 00:48:14,568
обеспечивает большую эффективность. Если бы мы не поддерживали разделение внутренних

478
00:48:14,648 --> 00:48:21,658
данных memoryview, то субинтерпретаторы были бы, вероятно,

479
00:48:21,698 --> 00:48:28,988
менее мощными в определенных ситуациях. Но загвоздка в том, что если

480
00:48:29,029 --> 00:48:32,653
вы это делаете, вам все равно нужно беспокоиться о потокобезопасности. Потому что теперь эти

481
00:48:32,713 --> 00:48:36,819
два интерпретатора не разделяют GIL. У них нет никакой потокобезопасности между

482
00:48:36,879 --> 00:48:44,549
ними. Так что теперь, если вы пишете в этот memoryview с одной стороны, и вы

483
00:48:44,589 --> 00:48:48,274
пишете в него с другой, у вас возникают все проблемы с потокобезопасностью. Так что вы должны

484
00:48:48,334 --> 00:48:51,638
управлять этим осторожно. Это не слишком сложно, но вы соглашаетесь на это. Это главное.

485
00:48:51,658 --> 00:48:57,526
Вы соглашаетесь на это. Я как раз хотел спросить вас, верно ли это для всех буферов,

486
00:48:57,926 --> 00:49:03,453
читаемых и записываемых буферов? И я полагаю, что это верно для обоих,

487
00:49:03,753 --> 00:49:08,699
да? Ну, так вот, протокол буфера, он предоставляет вам механизм, чтобы сказать: "это

488
00:49:08,759 --> 00:49:13,905
буфер только для чтения", но ограничений нет. Я имею в виду, вы разделяете эту

489
00:49:13,965 --> 00:49:18,53
память. Так что на практике ограничений нет. Это зависит от

490
00:49:18,651 --> 00:49:25,499
пользователя буфера, говорить, будет ли он на самом деле изменяться или нет. Так что я

491
00:49:25,559 --> 00:49:34,755
думаю, у нас может быть, я не... мне нужно посмотреть, но я думаю, по крайней мере, изначально я сделал

492
00:49:34,815 --> 00:49:41,125
так, что он отклоняет буферы, которые не помечены как "только для чтения". Но я не

493
00:49:41,185 --> 00:49:50,016
помню. Может быть, я ослабил это. Я не помню. Но в любом случае, это не

494
00:49:50,176 --> 00:49:54,822
предотвращает модификацию этих разделяемых данных вообще. Когда мы сравниваем два случая

495
00:49:54,902 --> 00:50:01,45
совместного использования объектов, которые являются сложными объектами, некоторыми пользовательскими, мы сравниваем два

496
00:50:01,611 --> 00:50:05,636
варианта использования. Один из них — multiprocessing, а второй —

497
00:50:05,716 --> 00:50:13,849
субинтерпретаторы. Какой из них быстрее, очевидно? Субинтерпретаторы. У них есть

498
00:50:13,969 --> 00:50:19,677
много преимуществ потоков с изоляцией нескольких процессов.

499
00:50:21,098 --> 00:50:25,444
Сам по себе multiprocessing немного сложен, если вы используете

500
00:50:25,504 --> 00:50:31,792
concurrent.futures. Это немного упрощает все дело. И для большинства случаев использования

501
00:50:31,832 --> 00:50:39,001
concurrent.futures — это, вероятно, то, что вам нужно. Но использование multiprocessing

502
00:50:39,061 --> 00:50:47,697
самого по себе как модуля — не самая простая вещь. Но что касается эффективности,

503
00:50:47,757 --> 00:50:54,084
то есть множество способов, которыми несколько интерпретаторов более эффективны,

504
00:50:54,244 --> 00:51:02,493
чем несколько процессов. И в зависимости от платформы, особенно быстрее. Я

505
00:51:02,513 --> 00:51:08,3
имею в виду, на Windows есть множество причин, почему несколько процессов намного

506
00:51:08,34 --> 00:51:17,374
медленнее или менее эффективны, чем работа в одном и том же процессе. Так что есть

507
00:51:17,654 --> 00:51:22,559
такие вещи, как общение между процессами и общение между

508
00:51:22,639 --> 00:51:26,664
интерпретаторами. Между интерпретаторами может быть намного эффективнее по ряду

509
00:51:26,724 --> 00:51:33,13
причин. И прямо сейчас, в 3.14, реализация, как она есть, более

510
00:51:33,17 --> 00:51:38,076
эффективна, чем multiprocessing, но также есть много возможностей, чтобы сделать

511
00:51:38,116 --> 00:51:44,208
ее значительно более эффективной. Э-э, мы еще не там. Мы доберемся. Но

512
00:51:44,728 --> 00:51:55,006
это просто быстрее, запуск нескольких интерпретаторов быстрее. Вы можете использовать больше

513
00:51:55,046 --> 00:52:00,536
интерпретаторов, чем вы можете использовать процессов в целом. Когда вы используете несколько

514
00:52:00,596 --> 00:52:07,308
процессов, каждому процессу выделяется набор системных ресурсов.

515
00:52:07,408 --> 00:52:13,765
Эти ресурсы могут быть довольно ограничены. Количество процессов или идентификаторов процессов,

516
00:52:13,826 --> 00:52:20,38
или, в некоторой степени, есть множество других ресурсов, которые я не помню

517
00:52:20,421 --> 00:52:25,093
навскидку. И когда вы используете несколько интерпретаторов в одном и том же процессе,

518
00:52:26,014 --> 00:52:30,34
они все разделяют эти конкретные ресурсы. И поэтому они не

519
00:52:30,421 --> 00:52:37,071
исчерпываются в системе. При определенных масштабах есть определенные

520
00:52:37,131 --> 00:52:41,858
проекты, которые столкнулись с этими ограничениями при использовании нескольких процессов, с которыми они

521
00:52:41,898 --> 00:52:46,104
не столкнулись бы, если бы использовали несколько интерпретаторов, но без

522
00:52:46,164 --> 00:52:53,793
ущерба для степени изоляции. Хорошо. Это звучит потрясающе, потому что я думаю,

523
00:52:53,853 --> 00:53:00,39
многие люди очень расстроены из-за использования памяти multiprocessing, и они

524
00:53:00,43 --> 00:53:05,663
хотят, чтобы их вычисления были быстрее, и, по сути, это был их единственный способ сделать это.

525
00:53:05,643 --> 00:53:11,315
А теперь у них есть варианты. Это действительно круто. Еще одна вещь, о которой мы должны поговорить, —

526
00:53:11,375 --> 00:53:21,054
это AsyncIO, потому что это также связано с оптимизацией задач ввода-вывода. И

527
00:53:21,095 --> 00:53:29,729
прямо сейчас AsyncIO работает только в одном процессе в одном потоке, и, по сути, у него

528
00:53:29,749 --> 00:53:38,181
есть один GIL, и нет возможности для его масштабирования. Как мы можем улучшить производительность AsyncIO

529
00:53:38,421 --> 00:53:44,91
с помощью субинтерпретаторов? Да, это хороший вопрос. Я не

530
00:53:44,95 --> 00:53:51,499
много думал об этом, но то, что я знаю об AsyncIO, в основном заключается в том, что

531
00:53:51,519 --> 00:53:58,802
у вас есть ваш цикл событий или ваш... это цикл событий? Да. Так что у вас есть ваш цикл событий.

532
00:53:58,822 --> 00:54:10,981
Вы можете использовать несколько потоков с асинхронностью, это проблематично, и я не знаю,

533
00:54:11,321 --> 00:54:17,891
чтобы это действительно работало правильно. Может быть, люди это делают, или, может быть, это работает в некоторой

534
00:54:17,951 --> 00:54:24,76
степени, но есть какое-то глобальное состояние интерпретатора, которое мешает этому

535
00:54:24,86 --> 00:54:30,949
работать правильно. Если у вас есть цикл событий, работающий в каждом интерпретаторе,

536
00:54:31,79 --> 00:54:39,949
то единственное препятствие, которое у вас есть, — это передача данных из одного интерпретатора в

537
00:54:40,049 --> 00:54:45,678
другой, что мы и так решаем независимо. И теперь все, что нам

538
00:54:45,718 --> 00:54:54,914
нужно, — это просто кусок, где мы можем подключить к AsyncIO возможность выхода из... или

539
00:54:55,374 --> 00:55:02,317
ожидания от интерпретатора. Этого сейчас не существует. Это то, что, я уверен,

540
00:55:02,437 --> 00:55:07,124
люди будут ждать. Но ожидание от одной из этих очередей между интерпретаторами,

541
00:55:07,204 --> 00:55:11,09
я не вижу, почему бы это не было осуществимо. Может быть, иметь абстракцию

542
00:55:11,15 --> 00:55:17,039
вокруг цикла событий, работающего в другом интерпретаторе, и затем вы можете ожидать от

543
00:55:17,099 --> 00:55:25,259
этого объекта, или я не знаю. Я не уверен в практичности этого, но я

544
00:55:25,299 --> 00:55:29,946
не знаю о каких-либо препятствиях для людей, которые бы с этим разбирались. И я не знаю, что это

545
00:55:29,986 --> 00:55:35,014
было бы так уж сложно. Я также не знаю, каковы обязательно случаи использования для того, чтобы

546
00:55:35,054 --> 00:55:40,061
воспользоваться преимуществами asyncio плюс субинтерпретаторы, но я уверен, что есть

547
00:55:40,121 --> 00:55:48,889
некоторые. Звучит как очень интересный исследовательский проект. Я думаю, он будет очень большим по

548
00:55:48,949 --> 00:55:54,077
популярности и ажиотажу, потому что многие любят AsyncIO и любят

549
00:55:55,159 --> 00:56:01,869
масштабировать его. Вы можете стать героем Python. Интересно, если вы посмотрите на

550
00:56:01,929 --> 00:56:07,35
PEP 554, это оригинальный PEP для модуля стандартной библиотеки. И большая причина,

551
00:56:07,41 --> 00:56:13,077
почему я создал новый PEP, заключается в том, что 554 становился действительно большим. И большая часть этого

552
00:56:13,237 --> 00:56:20,907
была потому, что у меня был длинный раздел обо всех вещах, которые не были частью PEP 554. Если

553
00:56:20,947 --> 00:56:25,673
я правильно помню, одной из этих вещей была поддержка AsyncIO с

554
00:56:25,713 --> 00:56:29,598
субинтерпретаторами, о которых мы говорим. Это была одна вещь, о которой я сказал: "Ну,

555
00:56:29,678 --> 00:56:36,193
мы не будем пытаться решить это здесь". Так что сейчас прекрасное время для людей начать

556
00:56:36,233 --> 00:56:41,601
думать о том, как это решить. Еще одна большая тема, которую мы еще не затронули, — это

557
00:56:42,082 --> 00:56:49,513
сборка мусора. Так что сборщик мусора на самом деле не играет большой роли. У каждого интерпретатора

558
00:56:49,553 --> 00:56:53,439
есть своя собственная сборка мусора. У каждого интерпретатора есть свой собственный набор объектов.

559
00:56:53,739 --> 00:57:02,737
На самом деле нет места для разделения объектов между интерпретаторами, объектов,

560
00:57:02,777 --> 00:57:07,563
которые принадлежат интерпретатору. Может быть, когда-нибудь мы это решим. Это

561
00:57:07,603 --> 00:57:11,808
то, что стоит изучить. Но с такой основой, это не является частью

562
00:57:11,868 --> 00:57:19,537
этого. И из-за этого объекты собираются сборщиком мусора того интерпретатора,

563
00:57:19,637 --> 00:57:26,044
который ими владеет. Ключевой момент в том, что если у нас есть какие-либо ссылки на объект, которые

564
00:57:27,105 --> 00:57:32,974
принадлежат, ссылки принадлежат другому интерпретатору. И есть способы

565
00:57:33,034 --> 00:57:40,665
сделать это. Мы делаем это в некоторых случаях. Ну, эти объекты, исходный

566
00:57:40,825 --> 00:57:46,513
объект, его счетчик ссылок отражает это. Так что ссылка, принадлежащая другому

567
00:57:46,533 --> 00:57:54,97
интерпретатору, отражается большим счетчиком ссылок в исходном объекте. И

568
00:57:55,3 --> 00:57:59,842
из-за этого этот объект никогда не будет учтен счетчиком ссылок, пока другой

569
00:57:59,902 --> 00:58:05,315
интерпретатор не освободит эту ссылку. Так что сборка мусора на самом деле не вступает

570
00:58:05,335 --> 00:58:11,814
в игру, пока другой интерпретатор держит ссылку на объект.

571
00:58:11,874 --> 00:58:17,46
исходный объект. Так как мы можем сделать субинтерпретаторы быстрее? Как мы можем сделать

572
00:58:18,141 --> 00:58:23,927
их потребление памяти меньше? И как мы можем улучшить различные части

573
00:58:23,967 --> 00:58:28,792
производительности? Как использовать меньше памяти? Есть много возможностей.

574
00:58:29,452 --> 00:58:37,04
Одна из вещей, которую я хочу попробовать, — это найти способ разделять модули между

575
00:58:37,1 --> 00:58:44,386
интерпретаторами и разделять типы между интерпретаторами. Если мы сможем решить эти две проблемы,

576
00:58:44,707 --> 00:58:49,794
и поскольку количество типов и количество модулей относительно невелико

577
00:58:50,335 --> 00:58:56,103
по сравнению с количеством объектов в интерпретаторе, то это должно быть

578
00:58:56,143 --> 00:59:00,25
управляемым. Так что если мы сделаем их общими, это упростит количество вещей. И это

579
00:59:00,37 --> 00:59:09,588
также означает, что память типов и модулей используется совместно, и поэтому мы не

580
00:59:09,828 --> 00:59:13,775
дублируем эту память. Следовательно, мы используем меньше памяти. Другой вариант —

581
00:59:14,636 --> 00:59:20,606
идея копирования при записи. Так что внедрить в реализацию Python

582
00:59:20,646 --> 00:59:26,436
некоторый механизм копирования при записи, где мы разделяем это

583
00:59:26,476 --> 00:59:30,061
все. Так что у основного интерпретатора есть куча всего, куча объектов

584
00:59:30,082 --> 00:59:36,718
и других данных. И когда мы создаем субинтерпретатор, пусть он держит ссылки

585
00:59:36,758 --> 00:59:41,435
на исходные вещи. Но если что-то изменяется, то он создает копию,

586
00:59:41,455 --> 00:59:47,197
как обычный механизм копирования при записи. Это тоже может очень помочь. Один

587
00:59:47,317 --> 00:59:53,624
вариант — есть механизм, используемый в XEmacs, и не только в XEmacs, он используется в

588
00:59:53,644 --> 01:00:00,171
различных проектах. Но идея в том, что в определенный стабильный момент в работе вашей программы

589
01:00:00,251 --> 01:00:08,66
вы делаете снимок памяти. И вы также, вы обрабатываете этот

590
01:00:08,7 --> 01:00:14,879
снимок, определяете смещения в различные вещи, так что от этого

591
01:00:14,979 --> 01:00:21,105
указателя к этой вещи, но на самом деле это смещение от этой другой

592
01:00:21,145 --> 01:00:26,31
вещи в нашем снимке памяти. Так что теперь у вас есть снимок, вы сохраняете его

593
01:00:26,41 --> 01:00:31,696
на диск. И теперь, когда вы запускаетесь, вы загружаете этот снимок. Это как статически

594
01:00:31,816 --> 01:00:38,282
выделенная память. Она отображается в память и очень быстрая, верно? И теперь у вас есть

595
01:00:38,322 --> 01:00:43,871
снимок, вы исправляете указатели, основываясь на этих смещениях к ссылкам и всему

596
01:00:43,931 --> 01:00:51,058
этому. И теперь ваша память в том состоянии, в котором она была, когда вы запускали ее в первый

597
01:00:51,118 --> 01:00:55,563
раз и делали снимок. Так что теперь она как бы восстановлена до этого состояния,

598
01:00:56,163 --> 01:01:04,572
которое почти всегда будет таким же, как каждый раз, когда вы запускаете Python.

599
01:01:04,873 --> 01:01:09,551
Это очень похоже на то, как делают виртуальные машины. Да. Да, почти, за исключением того, что с

600
01:01:09,591 --> 01:01:14,339
ними им не нужно исправлять указатели и все такое. Это что-то типа,

601
01:01:14,379 --> 01:01:20,328
что происходит, когда операционная система загружает программу. Так что

602
01:01:20,388 --> 01:01:27,66
есть много предыдущего опыта о том, как это решить. И это одна вещь. Это означает,

603
01:01:27,84 --> 01:01:34,879
что вы бы запускали интерпретатор на основе этого снимка. И

604
01:01:35,039 --> 01:01:40,028
может быть, знаете, вам пришлось бы разобраться с копированием или копированием при записи или чем-то еще. Но

605
01:01:40,749 --> 01:01:47,201
так запуск был бы намного быстрее. Вы бы использовали меньше памяти. И есть ряд

606
01:01:47,221 --> 01:01:54,085
других преимуществ тоже. Так что это, и не только это, но это также просто сделало бы

607
01:01:54,145 --> 01:01:59,818
запуск Python быстрее, что принесло бы пользу всем. Что касается обмена данными

608
01:01:59,858 --> 01:02:04,208
между интерпретаторами, знаете, реализация, которую я сделал для этого, для

609
01:02:04,248 --> 01:02:11,736
очереди, действительно наивна. Я сосредоточился на правильности. Думаю, я сделал это правильно. Но

610
01:02:11,796 --> 01:02:16,241
я не тратил много времени, чтобы сделать ее быстрой. Так что, вероятно, много

611
01:02:17,262 --> 01:02:21,846
дублирующихся усилий, много лишних блокировок, много всего, что не нужно

612
01:02:21,866 --> 01:02:26,991
там. И поэтому их можно было бы сделать намного быстрее. Есть механизм, который они

613
01:02:27,172 --> 01:02:32,757
используют. Они пытаются, по сути, очень эффективно копировать объект. Есть

614
01:02:32,817 --> 01:02:36,841
механизм для эффективного копирования для некоторых объектов. Если это не

615
01:02:36,861 --> 01:02:44,697
работает, он откатывается к pickle. А pickle не супербыстрый. Так что есть вещи, которые

616
01:02:44,737 --> 01:02:50,563
мы могли бы сделать, чтобы сделать использование pickle значительно быстрее, что сделало бы

617
01:02:50,583 --> 01:02:57,449
общение между интерпретаторами через очереди намного быстрее. Но это еще не

618
01:02:57,489 --> 01:03:01,553
сделано. Также можно было бы сделать немного более эффективно с точки зрения памяти, хотя я

619
01:03:02,334 --> 01:03:09,013
не думаю, что там все слишком плохо. Также есть место для того, чтобы люди придумали механизмы для

620
01:03:09,093 --> 01:03:14,838
безопасной передачи данных или объектов между интерпретаторами. Многое из этого не

621
01:03:14,879 --> 01:03:20,804
потребует поддержки от самой среды выполнения, что означает, что создание

622
01:03:20,904 --> 01:03:25,489
модуля расширения вполне осуществимо. Есть много возможностей для улучшения

623
01:03:25,549 --> 01:03:31,395
эффективности, как по памяти, так и по времени
для этих различных

624
01:03:31,435 --> 01:03:35,78
механизмов, для которых мы построили эту
основу. У меня также есть еще один

625
01:03:35,82 --> 01:03:41,369
вопрос о работе сообщества. Какие
пакеты, какие библиотеки вы

626
01:03:41,429 --> 01:03:47,999
ожидаете или, может быть, надеетесь однажды увидеть?
Какие идеи вы хотите выделить, которые

627
01:03:48,16 --> 01:03:53,228
могут заинтересовать людей?
Так что это интересно. Я не знаю,

628
01:03:53,288 --> 01:03:59,938
действительно ли будет много
случаев, когда люди будут выпускать инструменты.

629
01:04:00,038 --> 01:04:05,575
где пользователи будут
использовать несколько интерпретаторов напрямую.

630
01:04:05,836 --> 01:04:10,364
Будут, я уверен, есть
случаи, когда это имеет смысл. И я уверен,

631
01:04:10,424 --> 01:04:15,954
у нас будут такие библиотеки. И
знаете, есть, эм, я уверен,

632
01:04:16,014 --> 01:04:21,504
люди выпустят библиотеки, которые
реализуют CSP поверх нескольких интерпретаторов

633
01:04:21,625 --> 01:04:29,616
с более явным CSP API или
моделью акторов или чем-то еще. Это есть, но

634
01:04:29,656 --> 01:04:35,064
я ожидаю, что в итоге произойдет то, что
появится много библиотек, которые будут

635
01:04:35,144 --> 01:04:38,829
работать с использованием нескольких интерпретаторов,
и люди будут продолжать использовать эти

636
01:04:38,889 --> 01:04:42,814
библиотеки так же, как они их
уже используют. Особенно, например,

637
01:04:42,914 --> 01:04:51,065
с веб-фреймворками. Я определенно вижу, как
их можно было бы адаптировать для использования нескольких

638
01:04:51,086 --> 01:04:57,487
интерпретаторов, где они обрабатывают
каждый запрос, много разных вариантов

639
01:04:57,547 --> 01:05:03,738
которые могут быть в этой области. С обработкой
данных, в общем-то, та же история. Может быть,

640
01:05:03,798 --> 01:05:07,645
если люди сейчас используют потоки напрямую,
они будут работать в направлении

641
01:05:07,725 --> 01:05:12,553
внедрения нескольких интерпретаторов таким же
образом. Уже есть исполнитель пула

642
01:05:12,573 --> 01:05:17,145
интерпретаторов, который работает так же, как
исполнитель пула потоков и исполнитель пула процессов.

643
01:05:17,165 --> 01:05:23,134
Так что люди уже могут на него переключиться.
Я думаю, что большая часть использования

644
01:05:23,214 --> 01:05:28,963
нескольких интерпретаторов, которую мы увидим в
краткосрочной перспективе, будет, с одной стороны,

645
01:05:29,744 --> 01:05:36,814
библиотеки, как бы встраивающие их под капот.
А с другой стороны, может быть, некоторые

646
01:05:36,934 --> 01:05:44,509
дополнительные удобства для людей, которые
хотят использовать их напрямую, а такие

647
01:05:44,549 --> 01:05:49,015
случаи использования есть, и это имеет смысл. Я
думаю, что большинство людей в своих приложениях

648
01:05:50,057 --> 01:05:56,406
не будут использовать их напрямую. Я думаю,
что самое творческое использование

649
01:05:56,426 --> 01:06:00,071
нескольких интерпретаторов на самом деле будет
в случаях, когда люди

650
01:06:00,792 --> 01:06:04,798
общаются между ними, даже
передавая или даже разделяя объекты.

651
01:06:05,504 --> 01:06:09,287
люди придумают библиотеки,
в которых они будут это исследовать и использовать,

652
01:06:09,327 --> 01:06:17,475
что, я думаю, дает много простора
для этого в сообществе. Потрясающе. Спасибо,

653
01:06:17,495 --> 01:06:24,521
Вам. У вас есть какие-нибудь социальные сети, которые вы хотите
продвигать? Может быть, какие-то тикеты на GitHub,

654
01:06:24,882 --> 01:06:33,189
с которыми вам нужна помощь? Не очень
много. Я имею в виду, я работаю над руководством по

655
01:06:33,229 --> 01:06:38,942
параллелизму, над которым я работаю с
осени и как бы работал над ним время от времени.

656
01:06:39,964 --> 01:06:47,075
Я как бы отложил его пару месяцев
назад, чтобы сосредоточиться на том, чтобы

657
01:06:48,116 --> 01:06:52,784
материалы по модулю стандартной библиотеки были готовы
к работе. Но это то, к чему я

658
01:06:52,804 --> 01:06:59,754
вернусь. Мне всегда пригодится обратная связь
по этому поводу. Я позабочусь, чтобы у вас был

659
01:07:01,297 --> 01:07:07,203
номер на GitHub, я имею в виду, если вы просто поищете
проблему на GitHub о руководстве по параллелизму,

660
01:07:07,263 --> 01:07:14,233
вы его найдете. Оно будет прямо
здесь. Отлично. Я также работаю прямо сейчас. Так

661
01:07:14,274 --> 01:07:17,078
что я добавляю документацию для
модуля стандартной библиотеки, которая у меня была в

662
01:07:17,098 --> 01:07:24,629
3.14. И я уже внес большую часть материала. Я
думаю, это в довольно хорошем состоянии. Но одна

663
01:07:24,649 --> 01:07:28,735
вещь, в которой я хотел убедиться, — это
наличие руководства специально

664
01:07:29,356 --> 01:07:34,242
для нескольких интерпретаторов. И я
работаю над тем, чтобы внести его, вероятно,

665
01:07:34,302 --> 01:07:39,749
на этой неделе, если все пойдет хорошо, но посмотрим.
Так что это как бы отдельная вещь от

666
01:07:39,809 --> 01:07:44,535
общего руководства по параллелизму.
Руководство по параллелизму будет включать в себя кучу

667
01:07:44,555 --> 01:07:50,803
сравнений того, как бы вы решали некоторые
проблемы с различными моделями параллелизма,

668
01:07:50,843 --> 01:07:54,808
и как выглядит код, и чем он
отличается, и в чем он схож, и так

669
01:07:54,848 --> 01:08:03,229
далее. В то время как материалы по
субинтерпретаторам будут выглядеть совсем иначе, они будут

670
01:08:03,27 --> 01:08:09,824
сосредоточены только на нескольких интерпретаторах.
Я вам и эту ссылку дам. Потрясающе, это

671
01:08:09,865 --> 01:08:18,732
тоже будет здесь. Отлично. Спасибо,
Эрик, за то, что поделились своим опытом и

672
01:08:18,792 --> 01:08:23,197
историей субинтерпретаторов и вашими
мыслями о будущем этой функции.

673
01:08:23,638 --> 01:08:28,884
Я с нетерпением жду возможности использовать его в
продакшене. И я надеюсь, что наша аудитория

674
01:08:28,924 --> 01:08:34,03
многому у вас научится и ускорит
свои вычисления. И вот ваши

675
01:08:34,11 --> 01:08:38,655
задачи. Так что спасибо за создание субинтерпретаторов. И
спасибо, что поделились. Да, спасибо.

676
01:08:38,876 --> 01:08:41,719
Спасибо, что пригласили. Отлично. Пока-пока.
